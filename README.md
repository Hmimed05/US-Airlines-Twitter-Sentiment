# US-Airlines-Twitter-Sentiment
Three machine learning techniques are used – support vector machine, Naïve Bayes and neural networks. The accuracy of support vector machine, Naïve Bayes and neural network on validation data-set are 82%, 72% and 55% respectively.


Introduction:
- Twitter is most popular social networking website and is a real time micro blogging where news breaks first. Users interact by posting messages in the form of tweets that are restricted to 140 characters. It is always useful to classify the tweets for better information retrieval and decision making. In this project, we are performing sentiment analysis/text mining on tweets of US Airlines, applying machine learning techniques and implementing to neural networks (back propagation algorithm) to classify the tweets.
Problem statement:
	To Classify the tweets of the US Airlines as a positive, negative or neutral tweet. This can help customers to choose airlines with better service.

Proposed method:
- Idea of the project is to create a model that will classify the tweets into three categories: Positive tweet, Negative tweet or Neutral tweet. The data used in the project is the column tweet from the available dataset. Text mining/sentiment analysis is performed on the tweets using bag-of-words, term frequency-inverse document frequency and word2vec. Features are extracted by analyzing the results of these methods. Training set is created using the features as attributes and part of it is used as test set. Validation set is downloaded using the twitter API. Models are created to perform classification. To create a model, we used machine learning algorithms like support vector machine and naïve bayes and we implement back propagation algorithm. 

Text mining/sentiment analysis:
- The initial step in text mining is to remove the stop words. After removing stop words, tweets are extracted into three different documents depending on their class (Positive, Negative or Neutral). Separating the tweets helps in better feature extraction. Bag-of-words approach is performed on each document and hundred most frequently used words are retrieved. TF-IDF is applied to each document are hundred words with highest IDF is retrieved. Using these two sets of words sentiment analysis is performed. Words that help to identify the sentiments are extracted. For example: A tweet may contain a word good and it does not mean it is a positive sign. It may contain not good or no good. So, such sentiments are analyzed and set of words to identify the sentiments are grouped together. For each of the words extracted using bag-of-words and TF-IDF, wor2vec is applied and most related words are extracted. Duplicates are removed and final set words are extracted to a document. 


Feature extraction and dataset generation:
- The set of words extracted from the text mining/sentiment analysis is used as features for the dataset to be created. Using the features, tweets are parsed and training set is created. Ten percent of the records are used as testing set. These records are tagged with the target class.

Tweet streaming and validation dataset generation:
- Real-time tweets are streamed using Twitter Streaming API. Tweepy, a python library is used to stream tweets. To stream the tweets, we need to have twitter account and two set of credentials: 1. Consumer key, Consumer secret, Access token and Access token secret. These credentials provide authentication to stream and download the twitter data. The downloaded twitter data is parsed and using the features extracted, validation set is generated. These records are manually read and tagged.

Modelling:
- The library, sk-learn is used to generate modelling using support vector machine and Naïve Bayes. The training set and test set are directly passed into to function and model is created. These model is tested on the validation dataset. To develop a model using neural network, forward and backward propagation algorithms are implemented. A network with random weights are generated. The forward propagation is used to learn the error rate and back propagation algorithm is used to modify the weights to minimize the error rate. By repeating this process, a model is generated and for prediction the forward propagation algorithm is used.

Experiment and results:
- Three machine learning techniques are used – support vector machine, Naïve Bayes and neural networks. The accuracy of support vector machine, Naïve Bayes and neural network on validation dataset are 82%, 72% and 55% respectively. Since support vector machine is very efficient learning algorithm for numerical dataset, the model generated by it is good enough to produce results with error rate less than 19%.
- The Naïve Bayes algorithm works well on numerical dataset, but the dataset generated in this project has only two values. 0 – represents the given word is not present and 1- the given word is present. Initial adjustment is made by adding 1 to all the records in the dataset. The error rate was about 30% because the data did not help Naïve Bayes to identify the maximum likelihood in all cases.
- Finally, the neural network implemented by us failed to provide a better result because the dataset is very sparse. More than 60% of the data is 0 and this caused the neural networks to fail in this case. 

Conclusion:
- The accuracy of the prediction can be increased further by extraction few more key features by performing the data analysis. Support vector machine has a good chance to produce a better result for this kind of dataset. It was a valuable experience - implementing the neural networks, learning how it works internally.

References:
1. Twitter data of US Airlines - https://www.kaggle.com/crowdflower/twitter-airline-sentiment
2. How to Implement the Backpropagation Algorithm From Scratch In Python by James Browlee - http://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/
3. Twitter US Airline Recommendation Prediction - http://cs229.stanford.edu/proj2016spr/report/042.pdf
